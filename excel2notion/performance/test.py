import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import pickle


# 1. ëª¨ë¸ ë¡œë“œ
print("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
model = SentenceTransformer('dragonkue/multilingual-e5-small-ko-v2')
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")


# 2. ë°ì´í„° ë¡œë“œ
df = pd.read_excel("Restaurant_Recommendation_Final.xlsx")
df.columns = [col.strip().lower() for col in df.columns]
print(f" ì´ {len(df)}ê°œ í–‰ ë¡œë“œ")

train_data = df.iloc[0:800].reset_index(drop=True)
test_data = df.iloc[800:1000].reset_index(drop=True)

print(f"\nğŸ“Š Train: {len(train_data)}ê°œ | Test: {len(test_data)}ê°œ")

def get_text_baseline(row):
    """ê¸°ë³¸: ëª¨ë“  íŠ¹ì„± í¬í•¨"""
    parts = []
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    if 'ì¶”ì²œì´ìœ ' in row.index and pd.notna(row.get('ì¶”ì²œì´ìœ ')):
        reason = str(row.get('ì¶”ì²œì´ìœ ', ''))[:100]
        parts.append(reason)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_with_restaurant(row):
    """ì‹ë‹¹ëª… í¬í•¨"""
    parts = []
    
    # ì‹ë‹¹ëª… ì¶”ê°€
    if 'ì‹ë‹¹ëª…' in row.index and pd.notna(row.get('ì‹ë‹¹ëª…')):
        parts.append(str(row.get('ì‹ë‹¹ëª…', '')).strip())
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    if 'ì¶”ì²œì´ìœ ' in row.index and pd.notna(row.get('ì¶”ì²œì´ìœ ')):
        reason = str(row.get('ì¶”ì²œì´ìœ ', ''))[:100]
        parts.append(reason)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_with_region(row):
    """ì§€ì—­ í¬í•¨"""
    parts = []
    
    # ì§€ì—­ ì¶”ê°€
    if 'ì§€ì—­' in row.index and pd.notna(row.get('ì§€ì—­')):
        parts.append(str(row.get('ì§€ì—­', '')).strip())
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    if 'ì¶”ì²œì´ìœ ' in row.index and pd.notna(row.get('ì¶”ì²œì´ìœ ')):
        reason = str(row.get('ì¶”ì²œì´ìœ ', ''))[:100]
        parts.append(reason)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_with_both(row):
    """ì‹ë‹¹ëª… + ì§€ì—­ í¬í•¨"""
    parts = []
    
    # ì‹ë‹¹ëª… ì¶”ê°€
    if 'ì‹ë‹¹ëª…' in row.index and pd.notna(row.get('ì‹ë‹¹ëª…')):
        parts.append(str(row.get('ì‹ë‹¹ëª…', '')).strip())
    
    # ì§€ì—­ ì¶”ê°€
    if 'ì§€ì—­' in row.index and pd.notna(row.get('ì§€ì—­')):
        parts.append(str(row.get('ì§€ì—­', '')).strip())
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    if 'ì¶”ì²œì´ìœ ' in row.index and pd.notna(row.get('ì¶”ì²œì´ìœ ')):
        reason = str(row.get('ì¶”ì²œì´ìœ ', ''))[:100]
        parts.append(reason)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_price_menu_only(row):
    """í‰ê· ê°€ê²© + ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ë§Œ"""
    parts = []
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_foodtype_menu_only(row):
    """ìŒì‹ì¢…ë¥˜ + ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ë§Œ"""
    parts = []
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_price_foodtype_only(row):
    """í‰ê· ê°€ê²© + ìŒì‹ì¢…ë¥˜ë§Œ"""
    parts = []
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


def get_text_with_rating(row):
    """í‰ì  í¬í•¨"""
    parts = []
    
    # í‰ì  ì¶”ê°€
    if 'í‰ì ' in row.index and pd.notna(row.get('í‰ì ')):
        parts.append(str(row.get('í‰ì ', '')).strip())
    
    if 'ìŒì‹ì¢…ë¥˜' in row.index and pd.notna(row.get('ìŒì‹ì¢…ë¥˜')):
        parts.append(str(row.get('ìŒì‹ì¢…ë¥˜', '')))
    
    if 'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´' in row.index and pd.notna(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´')):
        menu = str(row.get('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', ''))[:50]
        parts.append(menu)
    
    if 'í‰ê· ê°€ê²©' in row.index and pd.notna(row.get('í‰ê· ê°€ê²©')):
        try:
            price = str(int(row.get('í‰ê· ê°€ê²©', '')))
            parts.append(price)
        except:
            pass
    
    if 'ì¶”ì²œì´ìœ ' in row.index and pd.notna(row.get('ì¶”ì²œì´ìœ ')):
        reason = str(row.get('ì¶”ì²œì´ìœ ', ''))[:100]
        parts.append(reason)
    
    text = " ".join(parts)
    return text if text else "ì •ë³´ ì—†ìŒ"


# 4. ì‹¤í—˜ ì„¤ì •
experiments = [
    {
        'name': 'Baseline (ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´+í‰ê· ê°€ê²©)',
        'get_text_func': get_text_baseline,
        'cache_file': 'train_embeddings_baseline.pkl'
    },
    {
        'name': 'í‰ê· ê°€ê²©+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´',
        'get_text_func': get_text_price_menu_only,
        'cache_file': 'train_embeddings_price_menu_only.pkl'
    },
    {
        'name': 'ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´',
        'get_text_func': get_text_foodtype_menu_only,
        'cache_file': 'train_embeddings_foodtype_menu_only.pkl'
    },
    {
        'name': 'í‰ê· ê°€ê²©+ìŒì‹ì¢…ë¥˜',
        'get_text_func': get_text_price_foodtype_only,
        'cache_file': 'train_embeddings_price_foodtype_only.pkl'
    },
    {
        'name': 'ì‹ë‹¹ëª… í¬í•¨',
        'get_text_func': get_text_with_restaurant,
        'cache_file': 'train_embeddings_with_restaurant.pkl'
    },
    {
        'name': 'ì§€ì—­ í¬í•¨',
        'get_text_func': get_text_with_region,
        'cache_file': 'train_embeddings_with_region.pkl'
    },
    {
        'name': 'í‰ì  í¬í•¨',
        'get_text_func': get_text_with_rating,
        'cache_file': 'train_embeddings_with_rating.pkl'
    }
]


# 5. ê° ì‹¤í—˜ ì‹¤í–‰
results = []

for exp_idx, exp in enumerate(experiments):
    print("\n" + "="*100)
    print(f"ğŸ”¬ ì‹¤í—˜ {exp_idx + 1}/{len(experiments)}: {exp['name']}")
    print("="*100)
    
    # Train ì„ë² ë”© ìƒì„± (ìºì‹±)
    try:
        print(f"\nğŸ’¾ ìºì‹œì—ì„œ Train ì„ë² ë”© ë¡œë“œ...")
        with open(exp['cache_file'], 'rb') as f:
            cache = pickle.load(f)
            train_embeddings = cache['embeddings']
            train_wines = cache['wines']
        print("âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ")
    except:
        print(f"\nğŸ”„ Train ì„ë² ë”© ìƒì„± ì¤‘...")
        train_texts = [exp['get_text_func'](row) for _, row in train_data.iterrows()]
        train_embeddings = model.encode(train_texts, show_progress_bar=True)
        
        train_wines = []
        for _, row in train_data.iterrows():
            wine = None
            if 'ì¶”ì²œì£¼ë¥˜' in row.index and pd.notna(row.get('ì¶”ì²œì£¼ë¥˜')):
                wine_str = str(row.get('ì¶”ì²œì£¼ë¥˜', '')).strip()
                wine_list = [w.strip() for w in wine_str.split(',')]
                wine = wine_list[0] if wine_list else None
            train_wines.append(wine)
        
        with open(exp['cache_file'], 'wb') as f:
            pickle.dump({'embeddings': train_embeddings, 'wines': train_wines}, f)
        print("âœ… Train ì„ë² ë”© ìƒì„± ë° ìºì‹œ ì €ì¥")
    
    # Test ë°ì´í„° ì¶”ì²œ
    print(f"\nğŸ”® Test ë°ì´í„° ì¶”ì²œ ì¤‘...")
    top_1_correct = 0
    
    for idx, test_row in test_data.iterrows():
        test_text = exp['get_text_func'](test_row)
        test_embedding = model.encode([test_text], show_progress_bar=False)[0]
        
        similarities = cosine_similarity(
            test_embedding.reshape(1, -1),
            train_embeddings
        )[0]
        
        top_5_idx = np.argsort(similarities)[-5:][::-1]
        top_5_similarities = similarities[top_5_idx]
        
        wine_scores = {}
        weights = [0.35, 0.25, 0.20, 0.15, 0.05]
        
        for i, train_idx in enumerate(top_5_idx):
            wine = train_wines[train_idx]
            if wine:
                score = weights[i] * top_5_similarities[i]
                if wine not in wine_scores or score > wine_scores[wine]:
                    wine_scores[wine] = score
        
        if wine_scores:
            recommended_wines = sorted(wine_scores.items(), 
                                       key=lambda x: x[1], reverse=True)[:3]
            recommended_wines = [w[0] for w in recommended_wines]
        else:
            recommended_wines = []
        
        actual_wine = None
        if 'ì¶”ì²œì£¼ë¥˜' in test_row.index and pd.notna(test_row.get('ì¶”ì²œì£¼ë¥˜')):
            wine_str = str(test_row.get('ì¶”ì²œì£¼ë¥˜', '')).strip()
            wine_list = [w.strip() for w in wine_str.split(',')]
            actual_wine = wine_list[0] if wine_list else None
        
        if actual_wine and recommended_wines and recommended_wines[0] == actual_wine:
            top_1_correct += 1
        
        if (idx + 1) % 50 == 0:
            print(f"  {idx + 1}/{len(test_data)} ì™„ë£Œ")
    
    # ì •í™•ë„ ê³„ì‚°
    total = len(test_data)
    accuracy = (top_1_correct / total * 100) if total > 0 else 0
    
    results.append({
        'ì‹¤í—˜ëª…': exp['name'],
        'ì •í™•ë„': accuracy,
        'ì •í™•ê°œìˆ˜': top_1_correct,
        'ì „ì²´ê°œìˆ˜': total
    })
    
    print(f"\nğŸ“Š {exp['name']} ì •í™•ë„: {accuracy:.2f}% ({top_1_correct}/{total})")


# 6. ê¸°ì—¬ë„ ë¶„ì„
print("\n" + "="*100)
print("ğŸ“Š Ablation Study ê²°ê³¼ ë° ê¸°ì—¬ë„ ë¶„ì„")
print("="*100)

results_df = pd.DataFrame(results)
print("\n" + results_df.to_string(index=False))

# ê¸°ì—¬ë„ ê³„ì‚°
baseline_acc = results[0]['ì •í™•ë„']  # Baseline (ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´+í‰ê· ê°€ê²©)
price_menu_acc = results[1]['ì •í™•ë„']  # í‰ê· ê°€ê²©+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´
foodtype_menu_acc = results[2]['ì •í™•ë„']  # ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´
price_foodtype_acc = results[3]['ì •í™•ë„']  # í‰ê· ê°€ê²©+ìŒì‹ì¢…ë¥˜
restaurant_acc = results[4]['ì •í™•ë„']  # ì‹ë‹¹ëª… í¬í•¨
region_acc = results[5]['ì •í™•ë„']  # ì§€ì—­ í¬í•¨
rating_acc = results[6]['ì •í™•ë„']  # í‰ì  í¬í•¨

print("\n" + "="*100)
print("ğŸ” ê¸°ì—¬ë„ ë¶„ì„")
print("="*100)

print(f"\nğŸ“Œ Baseline (ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´+í‰ê· ê°€ê²©): {baseline_acc:.2f}%")

# ìŒì‹ ì¢…ë¥˜ ê¸°ì—¬ë„(A) = Baseline - [í‰ê·  ê°€ê²© + ì‹œê·¸ë‹ˆì²˜ë©”ë‰´] ì •í™•ë„
A = baseline_acc - price_menu_acc
print(f"\nğŸœ ìŒì‹ ì¢…ë¥˜ ê¸°ì—¬ë„(A):")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   [í‰ê· ê°€ê²©+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´] ì •í™•ë„: {price_menu_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(A): {A:+.2f}%p")

# í‰ê·  ê°€ê²© ê¸°ì—¬ë„(B) = Baseline - [ìŒì‹ ì¢…ë¥˜ + ì‹œê·¸ë‹ˆì²˜ë©”ë‰´] ì •í™•ë„
B = baseline_acc - foodtype_menu_acc
print(f"\nğŸ’° í‰ê·  ê°€ê²© ê¸°ì—¬ë„(B):")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   [ìŒì‹ì¢…ë¥˜+ì‹œê·¸ë‹ˆì²˜ë©”ë‰´] ì •í™•ë„: {foodtype_menu_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(B): {B:+.2f}%p")

# ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê¸°ì—¬ë„(C) = Baseline - [í‰ê·  ê°€ê²© + ìŒì‹ ì¢…ë¥˜] ì •í™•ë„
C = baseline_acc - price_foodtype_acc
print(f"\nğŸ½ï¸  ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê¸°ì—¬ë„(C):")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   [í‰ê· ê°€ê²©+ìŒì‹ì¢…ë¥˜] ì •í™•ë„: {price_foodtype_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(C): {C:+.2f}%p")

# ì‹ë‹¹ëª… ê¸°ì—¬ë„(D) = ì‹ë‹¹ëª… í¬í•¨ í›„ ì •í™•ë„ - Baseline
D = restaurant_acc - baseline_acc
print(f"\nğŸª ì‹ë‹¹ëª… ê¸°ì—¬ë„(D):")
print(f"   ì‹ë‹¹ëª… í¬í•¨ ì •í™•ë„: {restaurant_acc:.2f}%")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(D): {D:+.2f}%p")

# ì§€ì—­ ê¸°ì—¬ë„(E) = ì§€ì—­ í¬í•¨ í›„ ì •í™•ë„ - Baseline
E = region_acc - baseline_acc
print(f"\nğŸ“ ì§€ì—­ ê¸°ì—¬ë„(E):")
print(f"   ì§€ì—­ í¬í•¨ ì •í™•ë„: {region_acc:.2f}%")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(E): {E:+.2f}%p")

# í‰ì  ê¸°ì—¬ë„(F) = í‰ì  í¬í•¨ í›„ ì •í™•ë„ - Baseline
F = rating_acc - baseline_acc
print(f"\nâ­ í‰ì  ê¸°ì—¬ë„(F):")
print(f"   í‰ì  í¬í•¨ ì •í™•ë„: {rating_acc:.2f}%")
print(f"   Baseline ì •í™•ë„: {baseline_acc:.2f}%")
print(f"   ê¸°ì—¬ë„(F): {F:+.2f}%p")

# ê° ê¸°ì—¬ë„ì˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
total_contribution = A + B + C + D + E + F
print(f"\n" + "="*100)
print("ğŸ“Š ê°€ì¤‘ì¹˜ ê³„ì‚°")
print("="*100)
print(f"\nì´ ê¸°ì—¬ë„ í•©: {total_contribution:.2f}%p")

if abs(total_contribution) > 0.0001:  # 0ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ê³„ì‚°
    weight_A = A / total_contribution
    weight_B = B / total_contribution
    weight_C = C / total_contribution
    weight_D = D / total_contribution
    weight_E = E / total_contribution
    weight_F = F / total_contribution
    
    print(f"\nğŸ¯ ê° íŠ¹ì„±ì˜ ê°€ì¤‘ì¹˜:")
    print(f"   ìŒì‹ ì¢…ë¥˜ ê°€ì¤‘ì¹˜: {weight_A:.4f} ({weight_A*100:.2f}%)")
    print(f"   í‰ê·  ê°€ê²© ê°€ì¤‘ì¹˜: {weight_B:.4f} ({weight_B*100:.2f}%)")
    print(f"   ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê°€ì¤‘ì¹˜: {weight_C:.4f} ({weight_C*100:.2f}%)")
    print(f"   ì‹ë‹¹ëª… ê°€ì¤‘ì¹˜: {weight_D:.4f} ({weight_D*100:.2f}%)")
    print(f"   ì§€ì—­ ê°€ì¤‘ì¹˜: {weight_E:.4f} ({weight_E*100:.2f}%)")
    print(f"   í‰ì  ê°€ì¤‘ì¹˜: {weight_F:.4f} ({weight_F*100:.2f}%)")
    
    # ê°€ì¤‘ì¹˜ í•© ê²€ì¦
    total_weight = weight_A + weight_B + weight_C + weight_D + weight_E + weight_F
    print(f"\n   ê°€ì¤‘ì¹˜ í•©: {total_weight:.4f} (ê²€ì¦)")
else:
    print("\nâš ï¸  ì´ ê¸°ì—¬ë„ í•©ì´ 0ì— ê°€ê¹Œì›Œ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    weight_A = weight_B = weight_C = weight_D = weight_E = weight_F = 0

# 7. ê²°ê³¼ ì €ì¥
print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")

# ìƒì„¸ ê²°ê³¼
detailed_results = []
for i, exp in enumerate(experiments):
    detailed_results.append({
        'ì‹¤í—˜ë²ˆí˜¸': i + 1,
        'ì‹¤í—˜ëª…': exp['name'],
        'ì •í™•ë„(%)': f"{results[i]['ì •í™•ë„']:.2f}",
        'ì •í™•ê°œìˆ˜': results[i]['ì •í™•ê°œìˆ˜'],
        'ì „ì²´ê°œìˆ˜': results[i]['ì „ì²´ê°œìˆ˜'],
        'Baseline ëŒ€ë¹„ ë³€í™”': f"{results[i]['ì •í™•ë„'] - baseline_acc:+.2f}%p"
    })

detailed_df = pd.DataFrame(detailed_results)
detailed_df.to_csv("ablation_study_results.csv", index=False, encoding='utf-8-sig')
print("âœ… ìƒì„¸ ê²°ê³¼ ì €ì¥: ablation_study_results.csv")

# ê¸°ì—¬ë„ ë° ê°€ì¤‘ì¹˜ ìš”ì•½
if abs(total_contribution) > 0.0001:
    contribution_summary = {
        'Baseline ì •í™•ë„': f"{baseline_acc:.2f}%",
        'ìŒì‹ì¢…ë¥˜ ê¸°ì—¬ë„(A)': f"{A:+.2f}%p",
        'í‰ê· ê°€ê²© ê¸°ì—¬ë„(B)': f"{B:+.2f}%p",
        'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê¸°ì—¬ë„(C)': f"{C:+.2f}%p",
        'ì‹ë‹¹ëª… ê¸°ì—¬ë„(D)': f"{D:+.2f}%p",
        'ì§€ì—­ ê¸°ì—¬ë„(E)': f"{E:+.2f}%p",
        'í‰ì  ê¸°ì—¬ë„(F)': f"{F:+.2f}%p",
        'ì´ ê¸°ì—¬ë„ í•©': f"{total_contribution:.2f}%p",
        'ìŒì‹ì¢…ë¥˜ ê°€ì¤‘ì¹˜': f"{weight_A:.4f} ({weight_A*100:.2f}%)",
        'í‰ê· ê°€ê²© ê°€ì¤‘ì¹˜': f"{weight_B:.4f} ({weight_B*100:.2f}%)",
        'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê°€ì¤‘ì¹˜': f"{weight_C:.4f} ({weight_C*100:.2f}%)",
        'ì‹ë‹¹ëª… ê°€ì¤‘ì¹˜': f"{weight_D:.4f} ({weight_D*100:.2f}%)",
        'ì§€ì—­ ê°€ì¤‘ì¹˜': f"{weight_E:.4f} ({weight_E*100:.2f}%)",
        'í‰ì  ê°€ì¤‘ì¹˜': f"{weight_F:.4f} ({weight_F*100:.2f}%)",
        'ìµœê³  ì •í™•ë„': f"{max([r['ì •í™•ë„'] for r in results]):.2f}%",
        'ìµœê³  ì •í™•ë„ ì‹¤í—˜': [r['ì‹¤í—˜ëª…'] for r in results if r['ì •í™•ë„'] == max([r['ì •í™•ë„'] for r in results])][0]
    }
else:
    contribution_summary = {
        'Baseline ì •í™•ë„': f"{baseline_acc:.2f}%",
        'ìŒì‹ì¢…ë¥˜ ê¸°ì—¬ë„(A)': f"{A:+.2f}%p",
        'í‰ê· ê°€ê²© ê¸°ì—¬ë„(B)': f"{B:+.2f}%p",
        'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê¸°ì—¬ë„(C)': f"{C:+.2f}%p",
        'ì‹ë‹¹ëª… ê¸°ì—¬ë„(D)': f"{D:+.2f}%p",
        'ì§€ì—­ ê¸°ì—¬ë„(E)': f"{E:+.2f}%p",
        'í‰ì  ê¸°ì—¬ë„(F)': f"{F:+.2f}%p",
        'ì´ ê¸°ì—¬ë„ í•©': f"{total_contribution:.2f}%p",
        'ìŒì‹ì¢…ë¥˜ ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'í‰ê· ê°€ê²© ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'ì‹œê·¸ë‹ˆì²˜ë©”ë‰´ ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'ì‹ë‹¹ëª… ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'ì§€ì—­ ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'í‰ì  ê°€ì¤‘ì¹˜': "ê³„ì‚° ë¶ˆê°€",
        'ìµœê³  ì •í™•ë„': f"{max([r['ì •í™•ë„'] for r in results]):.2f}%",
        'ìµœê³  ì •í™•ë„ ì‹¤í—˜': [r['ì‹¤í—˜ëª…'] for r in results if r['ì •í™•ë„'] == max([r['ì •í™•ë„'] for r in results])][0]
    }

summary_df = pd.DataFrame([contribution_summary])
summary_df.to_csv("ablation_contribution_summary.csv", index=False, encoding='utf-8-sig')
print("âœ… ê¸°ì—¬ë„ ë° ê°€ì¤‘ì¹˜ ìš”ì•½ ì €ì¥: ablation_contribution_summary.csv")

# 8. ì‹œê°í™” (í…ìŠ¤íŠ¸ ê¸°ë°˜)
print("\n" + "="*100)
print("ğŸ“ˆ ì •í™•ë„ ë¹„êµ ì°¨íŠ¸")
print("="*100)

max_acc = max([r['ì •í™•ë„'] for r in results])
for i, result in enumerate(results):
    bar_length = int((result['ì •í™•ë„'] / max_acc) * 50)
    bar = "â–ˆ" * bar_length
    change = result['ì •í™•ë„'] - baseline_acc
    change_str = f"({change:+.2f}%p)" if i > 0 else ""
    print(f"{result['ì‹¤í—˜ëª…']:30s}: {result['ì •í™•ë„']:6.2f}% {change_str:15s} {bar}")

print("\n" + "="*100)
print("ğŸ‰ Ablation Study ì™„ë£Œ!")
print("="*100)

print(f"\nâœ¨ í•µì‹¬ ë°œê²¬:")
contributions = [
    ('ìŒì‹ ì¢…ë¥˜', A),
    ('í‰ê·  ê°€ê²©', B),
    ('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', C),
    ('ì‹ë‹¹ëª…', D),
    ('ì§€ì—­', E),
    ('í‰ì ', F)
]
sorted_contributions = sorted(contributions, key=lambda x: x[1], reverse=True)

print(f"\n   ê¸°ì—¬ë„ ìˆœìœ„:")
for i, (name, contrib) in enumerate(sorted_contributions, 1):
    print(f"   {i}. {name}: {contrib:+.2f}%p")

if abs(total_contribution) > 0.0001:
    weights_list = [
        ('ìŒì‹ ì¢…ë¥˜', weight_A),
        ('í‰ê·  ê°€ê²©', weight_B),
        ('ì‹œê·¸ë‹ˆì²˜ë©”ë‰´', weight_C),
        ('ì‹ë‹¹ëª…', weight_D),
        ('ì§€ì—­', weight_E),
        ('í‰ì ', weight_F)
    ]
    sorted_weights = sorted(weights_list, key=lambda x: x[1], reverse=True)
    print(f"\n   ê°€ì¤‘ì¹˜ ìˆœìœ„:")
    for i, (name, weight) in enumerate(sorted_weights, 1):
        print(f"   {i}. {name}: {weight:.4f} ({weight*100:.2f}%)")

best_exp = max(results, key=lambda x: x['ì •í™•ë„'])
print(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {best_exp['ì‹¤í—˜ëª…']} ({best_exp['ì •í™•ë„']:.2f}%)")